{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a customized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import layers\n",
    "from tensorflow import keras\n",
    "import glob\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe you need to define a new model strucure, we can inherit class `BaseSRModel`.\n",
    "\n",
    "Here we use `SRCNN` as example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model establishing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import BaseSRModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It's noted that:**\n",
    "\n",
    "- In original paper, the author use \"valid\" padding when training, yet \"same\" padding when testing. Here as an example, we set padding \"valid\" and thus the label size should be modified later. See http://mmlab.ie.cuhk.edu.hk/projects/SRCNN.html for details\n",
    "\n",
    "- The `SRCNN` model pre-defined in module `models` use \"same\" padding by default.\n",
    "\n",
    "- Learning rate of the last layer in origional paper is set to 1e-5, others are set to 1e-4. I don't know how to do different learning rate for different layers in tensorflow... So I set all to 1e-5 for convenience..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRCNN(BaseSRModel):\n",
    "    \"\"\"\n",
    "    Using 9-1-5 model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, scale, model_name, channel=1):\n",
    "\n",
    "        super(SRCNN, self).__init__(scale, model_name, channel)\n",
    "        \n",
    "        # kernel size and number\n",
    "        self.f1 = 9\n",
    "        self.f2 = 1\n",
    "        self.f3 = 5\n",
    "\n",
    "        self.n1 = 64\n",
    "        self.n2 = 32\n",
    "\n",
    "    def create_model(self, load_weights=False, weights_path=None):\n",
    "\n",
    "        inp = super(SRCNN, self).create_model()\n",
    "\n",
    "        x = layers.Convolution2D(self.n1, (self.f1, self.f1),\n",
    "                                 activation='relu', padding='valid', name='level1')(inp)\n",
    "        x = layers.Convolution2D(self.n2, (self.f2, self.f2),\n",
    "                                 activation='relu', padding='valid', name='level2')(x)\n",
    "\n",
    "        out = layers.Convolution2D(self.channel, (self.f3, self.f3),\n",
    "                                   padding='valid', name='output')(x)\n",
    "\n",
    "        model = keras.Model(inp, out)\n",
    "\n",
    "        if load_weights:\n",
    "            weights_path = self.weights_path if weights_path is None else weights_path\n",
    "            model.load_weights(self.weight_path)\n",
    "            print(\"loaded model %s from %s\" % (self.model_name, weights_path))\n",
    "\n",
    "        self.model = model\n",
    "        return self\n",
    "\n",
    "    def lr_schedule(self, epoch, *args, **kwargs):\n",
    "        return 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-work is same as `train_models` notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"./Image/set14\" # Arbitrary\n",
    "valid_dir = \"./Image/set5\"\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "SCALE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.write2tfrec import write_dst_tfrec, load_tfrecord\n",
    "\n",
    "cache_dir = \"./cache\"\n",
    "os.makedirs(cache_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(\"./cache/set14_train_48x48.tfrec\"):\n",
    "    paths = list(glob.glob(os.path.join(train_dir, \"*\")))\n",
    "    write_dst_tfrec(paths, 10, 48, \"./cache/set14_train_48x48.tfrec\")\n",
    "    \n",
    "if not os.path.isfile(\"./cache/set5_valid_48x48.tfrec\"):\n",
    "    paths = list(glob.glob(os.path.join(valid_dir, \"*\")))\n",
    "    write_dst_tfrec(paths, 10, 48, \"./cache/set5_valid_48x48.tfrec\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing function here is a little different:**\n",
    "    \n",
    "- Lr-image should be upsample with `bicubic` kernel\n",
    "- Considering the padding issue, we need to center-crop Hr-patch to the same size as output of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocess import degrade_image\n",
    "from src.data_utils import center_crop\n",
    "\n",
    "def preprocess(hr):\n",
    "    lr, hr = degrade_image(hr, SCALE, method=2, restore_shape=True)\n",
    "    hr = center_crop(hr, (36, 36))\n",
    "    return lr, hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trdst = load_tfrecord(48, \"./cache/set14_train_48x48.tfrec\").map(preprocess).repeat()\n",
    "valdst = load_tfrecord(48, \"./cache/set5_valid_48x48.tfrec\").map(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model : SRCNN_X3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0621 21:30:27.754841  2524 training_utils.py:1353] Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " 1/20 [>.............................] - ETA: 50s - loss: 0.2249 - psnr_tf: 7.6447"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0621 21:30:30.805746  2524 callbacks.py:236] Method (on_train_batch_end) is slow compared to the batch update (0.143106). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/20 [========================>.....] - ETA: 24s - loss: 0.2299 - psnr_tf: 7.58 - ETA: 8s - loss: 0.2364 - psnr_tf: 8.1106 - ETA: 3s - loss: 0.2472 - psnr_tf: 7.623 - ETA: 1s - loss: 0.2378 - psnr_tf: 7.938 - ETA: 0s - loss: 0.2419 - psnr_tf: 7.7502\n",
      "Epoch 00001: saving model to ./weights/SRCNN_X3.h5\n",
      "20/20 [==============================] - 3s 161ms/step - loss: 0.2369 - psnr_tf: 7.9468 - val_loss: 0.1941 - val_psnr_tf: 8.9553\n",
      "Epoch 2/2\n",
      "17/20 [========================>.....] - ETA: 0s - loss: 0.1449 - psnr_tf: 8.850 - ETA: 0s - loss: 0.2276 - psnr_tf: 7.572 - ETA: 0s - loss: 0.2074 - psnr_tf: 8.410 - ETA: 0s - loss: 0.2153 - psnr_tf: 8.129 - ETA: 0s - loss: 0.2038 - psnr_tf: 8.554 - ETA: 0s - loss: 0.2090 - psnr_tf: 8.3432\n",
      "Epoch 00002: saving model to ./weights/SRCNN_X3.h5\n",
      "20/20 [==============================] - 1s 26ms/step - loss: 0.2030 - psnr_tf: 8.3938 - val_loss: 0.1595 - val_psnr_tf: 9.7366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.SRCNN at 0x22a2d889ac8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SRCNN(scale=SCALE, model_name=\"SRCNN\",\n",
    "                      channel=3).create_model(load_weights=False,\n",
    "                                              weights_path=None)\n",
    "model.fit(trdst,\n",
    "          valdst,\n",
    "          nb_epochs=2,\n",
    "          steps_per_epoch=20,\n",
    "          batch_size=16,\n",
    "          use_wn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
