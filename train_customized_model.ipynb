{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a customized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import layers\n",
    "from tensorflow import keras\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe you need to define a new model strucure, we can inherit class `BaseSRModel`.\n",
    "\n",
    "Here we use `SRCNN` as example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model establishing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import BaseSRModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It's noted that:**\n",
    "\n",
    "- In original paper, the author use \"valid\" padding when training, yet \"same\" padding when testing. Here as an example, we set padding \"valid\" and thus the label size should be modified later. See http://mmlab.ie.cuhk.edu.hk/projects/SRCNN.html for details\n",
    "\n",
    "- The `SRCNN` model pre-defined in module `models` use \"same\" padding by default.\n",
    "\n",
    "- Learning rate of the last layer in origional paper is set to 1e-5, others are set to 1e-4. I don't know how to do different learning rate for different layers in tensorflow... So I set all to 1e-5 for convenience..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRCNN(BaseSRModel):\n",
    "    \"\"\"\n",
    "    Using 9-1-5 model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, scale, model_name, channel=1):\n",
    "\n",
    "        super(SRCNN, self).__init__(scale, model_name, channel)\n",
    "        \n",
    "        # kernel size and number\n",
    "        self.f1 = 9\n",
    "        self.f2 = 1\n",
    "        self.f3 = 5\n",
    "\n",
    "        self.n1 = 64\n",
    "        self.n2 = 32\n",
    "\n",
    "    def create_model(self, load_weights=False, weights_path=None):\n",
    "\n",
    "        inp = super(SRCNN, self).create_model()\n",
    "\n",
    "        x = layers.Convolution2D(self.n1, (self.f1, self.f1),\n",
    "                                 activation='relu', padding='valid', name='level1')(inp)\n",
    "        x = layers.Convolution2D(self.n2, (self.f2, self.f2),\n",
    "                                 activation='relu', padding='valid', name='level2')(x)\n",
    "\n",
    "        out = layers.Convolution2D(self.channel, (self.f3, self.f3),\n",
    "                                   padding='valid', name='output')(x)\n",
    "\n",
    "        model = keras.Model(inp, out)\n",
    "\n",
    "        if load_weights:\n",
    "            weights_path = self.weights_path if weights_path is None else weights_path\n",
    "            model.load_weights(self.weight_path)\n",
    "            print(\"loaded model %s from %s\" % (self.model_name, weights_path))\n",
    "\n",
    "        self.model = model\n",
    "        return self\n",
    "\n",
    "    def lr_schedule(self, epoch, *args, **kwargs):\n",
    "        return 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-work is same as `train_models` notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"./Image/set14\" # Arbitrary\n",
    "valid_dir = \"./Image/set5\"\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "SCALE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.write2tfrec import write_dst_tfrec, load_tfrecord\n",
    "\n",
    "cache_dir = \"./cache\"\n",
    "os.makedirs(cache_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(\"./cache/set14_train_48x48.tfrec\"):\n",
    "    write_dst_tfrec(train_dir, 10, 48, \"./cache/set14_train_48x48.tfrec\")\n",
    "    \n",
    "if not os.path.isfile(\"./cache/set5_valid_48x48.tfrec\"):\n",
    "    write_dst_tfrec(valid_dir, 10, 48, \"./cache/set5_valid_48x48.tfrec\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing function here is a little different:**\n",
    "    \n",
    "- Lr-image should be upsample with `bicubic` kernel\n",
    "- Considering the padding issue, we need to center-crop Hr-patch to the same size as output of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocess import degrade_image\n",
    "from src.data_utils import center_crop\n",
    "\n",
    "def preprocess(hr):\n",
    "    lr, hr = degrade_image(hr, SCALE, method=2, restore_shape=True)\n",
    "    hr = center_crop(hr, (36, 36))\n",
    "    return lr, hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trdst = load_tfrecord(48, \"./cache/set14_train_48x48.tfrec\").map(preprocess,AUTOTUNE).repeat()\n",
    "valdst = load_tfrecord(48, \"./cache/set5_valid_48x48.tfrec\").map(preprocess, AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model : SRCNN_X3\n",
      "Epoch 1/2\n",
      "18/20 [==========================>...] - ETA: 35s - loss: 0.2503 - psnr_tf: 7.41 - ETA: 10s - loss: 0.3236 - psnr_tf: 6.09 - ETA: 2s - loss: 0.3069 - psnr_tf: 6.7184 - ETA: 1s - loss: 0.3025 - psnr_tf: 6.738 - ETA: 0s - loss: 0.2953 - psnr_tf: 7.0142\n",
      "Epoch 00001: saving model to ./weights/SRCNN_X3.h5\n",
      "20/20 [==============================] - 2s 115ms/step - loss: 0.2926 - psnr_tf: 7.0616 - val_loss: 0.2121 - val_psnr_tf: 8.5372\n",
      "Epoch 2/2\n",
      "17/20 [========================>.....] - ETA: 0s - loss: 0.2908 - psnr_tf: 6.479 - ETA: 0s - loss: 0.2397 - psnr_tf: 7.780 - ETA: 0s - loss: 0.2322 - psnr_tf: 8.126 - ETA: 0s - loss: 0.2353 - psnr_tf: 7.8873\n",
      "Epoch 00002: saving model to ./weights/SRCNN_X3.h5\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.2359 - psnr_tf: 7.9194 - val_loss: 0.1681 - val_psnr_tf: 9.5440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.SRCNN at 0x21d1bd7d668>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SRCNN(scale=SCALE, model_name=\"SRCNN\",\n",
    "                      channel=3).create_model(load_weights=False,\n",
    "                                              weights_path=None)\n",
    "model.fit(trdst,\n",
    "          valdst,\n",
    "          nb_epochs=2,\n",
    "          steps_per_epoch=20,\n",
    "          batch_size=16,\n",
    "          use_wn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
