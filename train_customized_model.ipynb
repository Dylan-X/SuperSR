{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a customized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import layers\n",
    "from tensorflow import keras\n",
    "import glob\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe you need to define a new model strucure, we can inherit class `BaseSRModel`.\n",
    "\n",
    "Here we use `SRCNN` as example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model establishing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import BaseSRModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It's noted that:**\n",
    "\n",
    "- In original paper, the author use \"valid\" padding when training, yet \"same\" padding when testing. Here as an example, we set padding \"valid\" and thus the label size should be modified later. See http://mmlab.ie.cuhk.edu.hk/projects/SRCNN.html for details\n",
    "\n",
    "- The `SRCNN` model pre-defined in module `models` use \"same\" padding by default.\n",
    "\n",
    "- Learning rate of the last layer in origional paper is set to 1e-5, others are set to 1e-4. I don't know how to do different learning rate for different layers in tensorflow... So I set all to 1e-5 for convenience..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRCNN(BaseSRModel):\n",
    "    \"\"\"\n",
    "    Using 9-1-5 model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, scale, model_name, channel=1):\n",
    "\n",
    "        super(SRCNN, self).__init__(scale, model_name, channel)\n",
    "        \n",
    "        # kernel size and number\n",
    "        self.f1 = 9\n",
    "        self.f2 = 1\n",
    "        self.f3 = 5\n",
    "\n",
    "        self.n1 = 64\n",
    "        self.n2 = 32\n",
    "\n",
    "    def create_model(self, load_weights=False, weights_path=None):\n",
    "\n",
    "        inp = super(SRCNN, self).create_model()\n",
    "\n",
    "        x = layers.Convolution2D(self.n1, (self.f1, self.f1),\n",
    "                                 activation='relu', padding='valid', name='level1')(inp)\n",
    "        x = layers.Convolution2D(self.n2, (self.f2, self.f2),\n",
    "                                 activation='relu', padding='valid', name='level2')(x)\n",
    "\n",
    "        out = layers.Convolution2D(self.channel, (self.f3, self.f3),\n",
    "                                   padding='valid', name='output')(x)\n",
    "\n",
    "        model = keras.Model(inp, out)\n",
    "\n",
    "        if load_weights:\n",
    "            weights_path = self.weights_path if weights_path is None else weights_path\n",
    "            model.load_weights(self.weight_path)\n",
    "            print(\"loaded model %s from %s\" % (self.model_name, weights_path))\n",
    "\n",
    "        self.model = model\n",
    "        return self\n",
    "\n",
    "    def lr_schedule(self, epoch, *args, **kwargs):\n",
    "        return 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-work is same as `train_models` notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"./Image/set14\" # Arbitrary\n",
    "valid_dir = \"./Image/set5\"\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "SCALE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.write2tfrec import write_dst_tfrec, load_tfrecord\n",
    "\n",
    "cache_dir = \"./cache\"\n",
    "os.makedirs(cache_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(\"./cache/set14_train_48x48.tfrec\"):\n",
    "    paths = list(glob.glob(os.path.join(train_dir, \"*\")))\n",
    "    write_dst_tfrec(paths, 10, 48, \"./cache/set14_train_48x48.tfrec\")\n",
    "    \n",
    "if not os.path.isfile(\"./cache/set5_valid_48x48.tfrec\"):\n",
    "    paths = list(glob.glob(os.path.join(valid_dir, \"*\")))\n",
    "    write_dst_tfrec(paths, 10, 48, \"./cache/set5_valid_48x48.tfrec\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing function here is a little different:**\n",
    "    \n",
    "- Lr-image should be upsample with `bicubic` kernel\n",
    "- Considering the padding issue, we need to center-crop Hr-patch to the same size as output of the model.\n",
    "- To follow the original paper, we need to transfer RGB image to Y channel only before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocess import degrade_image\n",
    "from src.data_utils import center_crop, rgb2ycbcr\n",
    "\n",
    "\n",
    "def preprocess(hr):\n",
    "    lr, hr = degrade_image(hr, SCALE, method=2, restore_shape=True)\n",
    "    hr = center_crop(hr, (36, 36))\n",
    "    # Using Y channel only\n",
    "    lr, hr = [rgb2ycbcr(x)[...,0][...,tf.newaxis] for x in [lr, hr]]\n",
    "    return lr, hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trdst = load_tfrecord(48, \"./cache/set14_train_48x48.tfrec\").map(preprocess).repeat()\n",
    "valdst = load_tfrecord(48, \"./cache/set5_valid_48x48.tfrec\").map(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model : SRCNN_X3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0623 15:51:50.750764  4944 training_utils.py:1353] Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " 1/20 [>.............................] - ETA: 45s - loss: 0.1226 - psnr_tf: 9.7831"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0623 15:51:53.370826  4944 callbacks.py:236] Method (on_train_batch_end) is slow compared to the batch update (0.162571). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/20 [=====================>........] - ETA: 21s - loss: 0.1352 - psnr_tf: 9.46 - ETA: 5s - loss: 0.1369 - psnr_tf: 9.8954 - ETA: 2s - loss: 0.1430 - psnr_tf: 9.781 - ETA: 0s - loss: 0.1501 - psnr_tf: 9.5017\n",
      "Epoch 00001: saving model to ./weights/SRCNN_X3.h5\n",
      "20/20 [==============================] - 3s 165ms/step - loss: 0.1434 - psnr_tf: 9.7495 - val_loss: 0.1236 - val_psnr_tf: 10.4736\n",
      "Epoch 2/2\n",
      "18/20 [==========================>...] - ETA: 0s - loss: 0.0953 - psnr_tf: 10.64 - ETA: 0s - loss: 0.1382 - psnr_tf: 9.4463 - ETA: 0s - loss: 0.1284 - psnr_tf: 10.13 - ETA: 0s - loss: 0.1246 - psnr_tf: 10.31 - ETA: 0s - loss: 0.1243 - psnr_tf: 10.2765\n",
      "Epoch 00002: saving model to ./weights/SRCNN_X3.h5\n",
      "20/20 [==============================] - 0s 20ms/step - loss: 0.1224 - psnr_tf: 10.3050 - val_loss: 0.0996 - val_psnr_tf: 11.4229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.SRCNN at 0x15c94422cc0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SRCNN(scale=SCALE, model_name=\"SRCNN\",\n",
    "                      channel=1).create_model(load_weights=False,\n",
    "                                              weights_path=None)\n",
    "model.fit(trdst,\n",
    "          valdst,\n",
    "          nb_epochs=2,\n",
    "          steps_per_epoch=20,\n",
    "          batch_size=16,\n",
    "          use_wn=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model's Info**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, None, 1)]   0         \n",
      "_________________________________________________________________\n",
      "level1 (Conv2D)              (None, None, None, 64)    5248      \n",
      "_________________________________________________________________\n",
      "level2 (Conv2D)              (None, None, None, 32)    2080      \n",
      "_________________________________________________________________\n",
      "output (Conv2D)              (None, None, None, 1)     801       \n",
      "=================================================================\n",
      "Total params: 8,129\n",
      "Trainable params: 8,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
